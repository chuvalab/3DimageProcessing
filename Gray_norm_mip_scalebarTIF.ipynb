{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1201a8a2",
   "metadata": {},
   "source": [
    "# Processing 3D microscope images into 2D .tif files\n",
    "\n",
    "In this jupyter notebook we will process 3D microscope images. We want to go from 3D .ims file generated by the Andor Dragonfly microscope to separate 2D .tif files for each channel, plus a scale bar image generated from the metadata of the .ims file. The resulting .tif files were combined into Adobe Photoshop using a separate script (also provided). \n",
    "\n",
    "This code performs several steps: \n",
    "- Autoscales the minimum and maximum signals to save time in Photoshop later. \n",
    "- Turns the 3D into 2D by maximum intensity projection (MIP). \n",
    "- Parses the 4 channel image into separate .tif files per channel. \n",
    "- Generates a scalebar .tif file based on metadata inside the .ims file. \n",
    "- 4 channel .tif files and scalebar .tif files are deposited into a separate folder. \n",
    "\n",
    "\n",
    "Of note: \n",
    "- In your directory where this .ipynb notebook is stored, please make a folder and name this \"Images\" -> put your .ims files in this \"Images\" folder. \n",
    "- In your directory where this .ipynb notebook is stored, please make a folder and name this \"Processed\"\n",
    "- The code assumes 16-bit images. \n",
    "- The code cannot handle video data (i.e., datasets with multiple timepoints). \n",
    "\n",
    "To start, we import the dependencies:\n",
    "- some packages part of the standard python library, like pathlib;\n",
    "- h5py is needed for opening ims files, which use the hdf5 standard;\n",
    "- numpy is needed for the processing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9395fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tifffile as tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f9d44",
   "metadata": {},
   "source": [
    "First, we define a few functions so that our code later on is cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b83883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abbreviated_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns an abbreviated name: creates a string of the first two characters of every word.\n",
    "    \"\"\"\n",
    "    return \"\".join([part[:2] for part in name.capitalize().split(\" \")])\n",
    "\n",
    "def rescale_data(data, desired_min=0, desired_max=2**16):\n",
    "    \"\"\"\n",
    "    Rescales numpy array (data) to be between desired_min and desired_max (linearly).\n",
    "    Defaults to 16 bit rescale.\n",
    "    \"\"\"\n",
    "    norm_data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    return (norm_data * (desired_max - desired_min)) + desired_min\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc2852",
   "metadata": {},
   "source": [
    "Next is the code that generates the output .tif files from your input .ims files. \n",
    "\n",
    "You will need to input your .ims filename in the code. In addition, the current scalebar length is for 50 um, but you may adjust this length if you wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bc6c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = Path(\"__file__\").parent\n",
    "\n",
    "# Make sure your '.ims' files are in this folder:\n",
    "SOURCE_FOLDER = ROOT_FOLDER / \"Images\"\n",
    "\n",
    "# Make sure you created a 'Processed' folder:\n",
    "PROCESSED_FOLDER = ROOT_FOLDER / \"Processed\"\n",
    "\n",
    "# Edit these if you want to change scale bar length, height or position:\n",
    "SCALE_BAR_LENGTH_MICROMETER = 50\n",
    "SCALE_BAR_HEIGHT_PIXEL = 9\n",
    "SCALE_BAR_RIGHT_BOTTOM_POSITION = (50, 50)\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "# Here, type the filename of your .ims file (DO NOT INCLUDE '.ims'):\n",
    "fname = \"YOUR_IMAGE_FILE_NAME\"\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "f = h5py.File(SOURCE_FOLDER / f\"{fname}.ims\", 'r')\n",
    "\n",
    "dataset = f.get(\"DataSet\")\n",
    "if not dataset:\n",
    "    raise ValueError(\"Dataset not found in image\")\n",
    "\n",
    "resolutions = list(dataset.keys())\n",
    "\n",
    "resolution = resolutions[0]\n",
    "resolution_dataset = dataset[resolution]\n",
    "timepoints = list(resolution_dataset.keys())\n",
    "if len(timepoints) > 1:\n",
    "    raise ValueError(\"This script does not know how to deal with datasets containing multiple timepoints. \" \\\n",
    "          \"Please create an issue on github and attach the image throwing this error.\")\n",
    "\n",
    "\n",
    "channels = resolution_dataset[timepoints[0]].items()\n",
    "\n",
    "image_data_dict = {}\n",
    "for channel_name, channel_data in channels:\n",
    "    data = channel_data[\"Data\"]\n",
    "    data_array = np.zeros(shape=data.shape, dtype=data.dtype)\n",
    "    data.read_direct(data_array)\n",
    "\n",
    "    # Get maximum signal of all layers so we end up with one image\n",
    "    reduced_image = np.maximum.reduce(data_array)\n",
    "\n",
    "    # Rescale image to be between 0 and 2**16\n",
    "    rescaled_image = rescale_data(reduced_image).astype(\"uint16\")\n",
    "\n",
    "    # Save to dictionary\n",
    "    image_data_dict[get_abbreviated_name(channel_name)] = rescaled_image\n",
    "\n",
    "    # Save to file\n",
    "    output_file = ROOT_FOLDER / \"Processed\" / f\"{fname}{get_abbreviated_name(resolution)}__{get_abbreviated_name(channel_name)}.tif\"\n",
    "    tiff.imwrite(output_file, rescaled_image)\n",
    "\n",
    "# Scale bar\n",
    "metadata = f[\"DataSetInfo\"][\"CustomData\"][\"PSF Settings Configuration V2\"]\n",
    "metadata_arr = np.zeros(metadata.shape, dtype=metadata.dtype)\n",
    "metadata.read_direct(metadata_arr)\n",
    "\n",
    "metadata_dict = json.loads(metadata_arr.tobytes().decode(\"iso-8859-1\"))\n",
    "\n",
    "resolution_x, resolution_y = metadata_dict[\"ResolutionX\"], metadata_dict[\"ResolutionY\"]\n",
    "assert resolution_x == resolution_y\n",
    "\n",
    "scale_bar_length_pixels = SCALE_BAR_LENGTH_MICROMETER / resolution_x\n",
    "\n",
    "# Mirror image shape and dtype of rescaled_image\n",
    "scale_bar_image = np.zeros(shape=rescaled_image.shape, dtype=rescaled_image.dtype)\n",
    "scale_bar = np.ones((SCALE_BAR_HEIGHT_PIXEL, round(scale_bar_length_pixels)))\n",
    "scale_bar_image[-scale_bar.shape[0]-SCALE_BAR_RIGHT_BOTTOM_POSITION[0]:-SCALE_BAR_RIGHT_BOTTOM_POSITION[0], -scale_bar.shape[1]-SCALE_BAR_RIGHT_BOTTOM_POSITION[1]:-SCALE_BAR_RIGHT_BOTTOM_POSITION[1]] = (2**16-1)*scale_bar\n",
    "\n",
    "output_file = PROCESSED_FOLDER / f\"{fname}{get_abbreviated_name(resolution)}__scale_bar_{SCALE_BAR_LENGTH_MICROMETER}micrometer.tif\"\n",
    "tiff.imwrite(output_file, scale_bar_image)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c13af",
   "metadata": {},
   "source": [
    "### Below are some lines to call information from the image metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0494f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f[\"DataSet\"]['ResolutionLevel 0']['TimePoint 0'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cf2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in arr:\n",
    "    print(e.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ea635",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\".join(str(e) for e in arr).replace(\"b'\", \"\").replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a58ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file = TiffFile(ROOT_FOLDER / \"example_tiff.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7e5c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in tiff_file.pages:\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"DataSetInfo\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"DataSetInfo\"][\"CustomData\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"DataSetInfo\"][\"CustomData\"][\"Protocol Configuration V2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a07b47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = f[\"DataSetInfo\"][\"CustomData\"][\"Protocol Configuration V2\"]\n",
    "arr = np.zeros(info.shape, dtype=info.dtype)\n",
    "info.read_direct(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93766ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "json.loads(arr.tobytes().decode(\"iso-8859-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba85348",
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"DataSetInfo\"][\"CustomData\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36aba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"DataSetInfo\"][\"CustomData\"][\"Protocol Configuration V2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d0441e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882c222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f20e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tif_tags.get(\"ImageDescription\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
